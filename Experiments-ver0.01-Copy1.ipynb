{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'data/ru-be-train.txt'\n",
    "TEST_FILE = 'data/ru-be-test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    " \n",
    "class Alphabet:\n",
    "    START = '__START__'\n",
    "    END = '_END_'\n",
    " \n",
    "    def __init__(self, max_length=MAX_LENGTH):\n",
    "        \"\"\"Initialize the class which works with letter and index representations of sequences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_length : int\n",
    "            The largest permitted length for sequence. Longer sequences are cropped.\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.letter2index_ = {Alphabet.START : 0, Alphabet.END : 1}\n",
    "        self.index2letter_ = [Alphabet.START, Alphabet.END]\n",
    "        \n",
    "    def get_index(self, letter):\n",
    "        if letter not in self.letter2index_:\n",
    "            self.letter2index_[letter] = len(self.index2letter_)\n",
    "            self.index2letter_.append(letter)\n",
    "        return self.letter2index_[letter]\n",
    "    \n",
    "    @property\n",
    "    def start_index(self):\n",
    "        return self.letter2index_[Alphabet.START]\n",
    "    \n",
    "    @property\n",
    "    def end_index(self):\n",
    "        return self.letter2index_[Alphabet.END]\n",
    "    \n",
    "    def index2letter(self, x):\n",
    "        return ''.join(self.index2letter_[index] for index in x)\n",
    "    \n",
    "    def letter2index(self, word):\n",
    "        lst = [self.get_index(letter) for letter in word]\n",
    "        return lst[:self.max_length - 1] + [self.get_index(Alphabet.END)] * max(1, self.max_length - len(lst))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index2letter_)\n",
    "    \n",
    "    # torch utils\n",
    "    def get_length(self, input_sequence):\n",
    "        \"\"\"Infers the lengths of sequences in batch\n",
    "        \n",
    "        \"\"\"\n",
    "        return (input_sequence == self.end_index).max(dim=1)[1] + 1\n",
    "    \n",
    "    def get_mask(self, input_sequence):\n",
    "        return (torch.cumsum(input_sequence == self.end_index, dim=1) < 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru = Alphabet()\n",
    "be = Alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pair_dataset(filename, alph1, alph2):\n",
    "    x, y = [], []\n",
    "    with open(filename, 'r') as ftr:\n",
    "        for line in ftr:\n",
    "            try:\n",
    "                word1, word2 = line.split()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            x.append(alph1.letter2index(word1))\n",
    "            y.append(alph2.letter2index(word2))\n",
    "    return np.array(x), np.array(y)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = load_pair_dataset(TRAIN_FILE, ru, be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_softmax_with_mask(entries, mask):\n",
    "    entries = entries[:,:,0]\n",
    "    maxs = entries.max(1, keepdim=True)[0]\n",
    "    #print(entries.shape, maxs.shape, mask.shape)\n",
    "    entries = torch.exp(entries - maxs) * mask\n",
    "    return entries / (entries.sum(dim=1, keepdim=True) + 1e-15)\n",
    "\n",
    "\n",
    "class MultiplicativeAttentionWithMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiplicativeAttentionWithMask, self).__init__()\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_hiddens, encoder_mask):\n",
    "        #print('#', decoder_hidden.unsqueeze(2).shape, encoder_hiddens.shape)\n",
    "        weights = torch.bmm(encoder_hiddens, decoder_hidden.unsqueeze(2))\n",
    "        weights = seq2seq_softmax_with_mask(weights, encoder_mask)\n",
    "        return torch.bmm(encoder_hiddens.transpose(1, 2), weights.unsqueeze(2))[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleGRUEncoder(nn.Module):\n",
    "    def __init__(self, alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUEncoder, self).__init__()\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(self.alphabet), embedding_dim=embedding_size)\n",
    "        self.gru = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_sequence):\n",
    "        batch_size = input_sequence.size(0)\n",
    "        embeddings = self.embedding(input_sequence)\n",
    "        out, _ = self.gru(embeddings)\n",
    "        return out, self.alphabet.get_mask(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGRUDecoderWithAttention(nn.Module):\n",
    "    def __init__(self, alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUDecoderWithAttention, self).__init__()\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(alphabet), embedding_dim=embedding_size)\n",
    "        self.gru_cell = nn.GRUCell(input_size=embedding_size, hidden_size=hidden_size)\n",
    "        self.logit_linear = nn.Linear(hidden_size, len(alphabet))\n",
    "        self.attention = MultiplicativeAttentionWithMask()\n",
    "        \n",
    "    def forward(self, token, prev_h, encoder_hs, encoder_mask):\n",
    "        embedding = self.embedding(token)\n",
    "        attention = self.attention(prev_h, encoder_hs, encoder_mask)\n",
    "        #h = self.gru_cell(torch.cat((embedding, attention), dim=1), prev_h)\n",
    "        h = self.gru_cell(embedding, prev_h)\n",
    "        out = self.logit_linear(h)\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleGRUSupervisedSeq2Seq(nn.Module):\n",
    "    def __init__(self, src_alphabet, dst_alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUSupervisedSeq2Seq, self).__init__()\n",
    "        self.encoder = SimpleGRUEncoder(src_alphabet, embedding_size, hidden_size)\n",
    "        self.h_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.decoder = SimpleGRUDecoderWithAttention(dst_alphabet, embedding_size, hidden_size)\n",
    "        \n",
    "    def start(self, batch_size):\n",
    "        return Variable(torch.from_numpy(np.repeat(self.decoder.alphabet.start_index, batch_size)))\n",
    "    \n",
    "    def middle_layer(self, out, mask):\n",
    "        #print(mask.sum(1))\n",
    "        return F.tanh(self.h_linear(out[range(out.shape[0]), mask.sum(1).long() - 1]))\n",
    "    \n",
    "    def forward(self, input_sequence, output_sequence):\n",
    "        enc_out, enc_mask = self.encoder(input_sequence)\n",
    "        dec_h = self.middle_layer(enc_out, enc_mask)\n",
    "        logits = []\n",
    "        for x in itertools.chain((self.start(output_sequence.size(0)),), output_sequence.transpose(0, 1)[:-1]):\n",
    "            out, dec_h = self.decoder(x, dec_h, enc_out, enc_mask)\n",
    "            logits.append(out)\n",
    "        return F.log_softmax(torch.stack(logits, dim=1), dim=-1)\n",
    "    \n",
    "    def translate(self, word, strategy='', max_length=30):\n",
    "        self.eval()\n",
    "        input_sequence = Variable(torch.from_numpy(np.array([model.encoder.alphabet.letter2index(word)])))\n",
    "        #print(input_sequence.shape)\n",
    "        enc_out, enc_mask = self.encoder(input_sequence)\n",
    "        hidden = self.middle_layer(enc_out, enc_mask)\n",
    "        token = self.start(1)\n",
    "        #print(token.shape, hidden.shape)\n",
    "        lst = []\n",
    "        for i in range(max_length):\n",
    "            out, hidden = self.decoder(token, hidden, enc_out, enc_mask)\n",
    "            token = out.max(1)[1]\n",
    "            #print(token, out)\n",
    "            lst.append(token.data[0])\n",
    "            if token.data[0] == self.decoder.alphabet.end_index:\n",
    "                break\n",
    "        return ''.join(model.decoder.alphabet.index2letter(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iterator(X, Y=None, batch_size=32):\n",
    "    assert Y is None or X.shape[0] == Y.shape[0]\n",
    "    ind = np.arange(X.shape[0])\n",
    "    np.random.shuffle(ind)\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        if Y is not None:\n",
    "            yield X[ind[i:i + batch_size]], Y[ind[i:i + batch_size]]\n",
    "        else:\n",
    "            yield X[ind[i:i + batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SimpleGRUSupervisedSeq2Seq(ru, be, 65, 256)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4200156688690186\n",
      "50 2.7578244786646855\n",
      "100 2.476875003504594\n",
      "150 2.2598716689577083\n",
      "200 2.1065707596336085\n",
      "250 2.01535555634957\n",
      "300 1.876824888887845\n",
      "350 1.7951637667744584\n",
      "400 1.6633113864847724\n",
      "450 1.6105036111570512\n",
      "500 1.5305022972919486\n",
      "550 1.5100637966351476\n",
      "600 1.408566580184508\n",
      "650 1.3746855779744651\n",
      "700 1.3140967167384212\n",
      "750 1.362946494030467\n",
      "800 1.2373363631253536\n",
      "850 1.2333869452152861\n",
      "900 1.2481400593116936\n",
      "950 1.1982124097484257\n",
      "1000 1.1443143058662386\n",
      "1050 1.157661315740318\n",
      "1100 1.0945232432196785\n",
      "1150 1.124057089954417\n",
      "1200 1.0943175566566314\n",
      "0 1.08509125660035\n",
      "50 1.0140618514667548\n",
      "100 0.9940563239478807\n",
      "150 0.9764196344233472\n",
      "200 0.9075055310552524\n",
      "250 0.9224959634548793\n",
      "300 0.9859912421201463\n",
      "350 0.8751660133411552\n",
      "400 0.9414093511153143\n",
      "450 0.878290504321146\n",
      "500 0.877956566902798\n",
      "550 0.8428007214933687\n",
      "600 0.8380512539265206\n",
      "650 0.8925832643114691\n",
      "700 0.7932154460600708\n",
      "750 0.8695035853252\n",
      "800 0.8293131378794679\n",
      "850 0.818125127833568\n",
      "900 0.816307650533187\n",
      "950 0.7984244203236033\n",
      "1000 0.7887849796399744\n",
      "1050 0.7860609758688928\n",
      "1100 0.7139842637402182\n",
      "1150 0.7699721388108627\n",
      "1200 0.7992287984212216\n",
      "0 0.7066482224123397\n",
      "50 0.6951046754793503\n",
      "100 0.7323513778137747\n",
      "150 0.6134636280958157\n",
      "200 0.6961073541532603\n",
      "250 0.6653479607127215\n",
      "300 0.6401466044219289\n",
      "350 0.662040813539293\n",
      "400 0.6367594199675148\n",
      "450 0.6914325919170654\n",
      "500 0.6681430985939749\n",
      "550 0.69217573123374\n",
      "600 0.6047991842103103\n",
      "650 0.6537848633052473\n",
      "700 0.6845255788238939\n",
      "750 0.6217837527159338\n",
      "800 0.6770777480243481\n",
      "850 0.6508065621105991\n",
      "900 0.636311950231592\n",
      "950 0.6042485038576196\n",
      "1000 0.6564242887844988\n",
      "1050 0.5983823427639439\n",
      "1100 0.6214567771538383\n",
      "1150 0.6504576372363886\n",
      "1200 0.6271502970702266\n",
      "0 0.5537473581801133\n",
      "50 0.533940519578491\n",
      "100 0.5271514176889853\n",
      "150 0.5131866099691724\n",
      "200 0.5533172812227539\n",
      "250 0.5240402871775509\n",
      "300 0.5185853930884083\n",
      "350 0.5101887167711943\n",
      "400 0.5526690328252055\n",
      "450 0.5775106778814829\n",
      "500 0.559892197348047\n",
      "550 0.49125580307912853\n",
      "600 0.5423154048111299\n",
      "650 0.5333596889509109\n",
      "700 0.5092591299741948\n",
      "750 0.5243381851497346\n",
      "800 0.5303818040870268\n",
      "850 0.47569172366376683\n",
      "900 0.5168854253963279\n",
      "950 0.5526164428748205\n",
      "1000 0.5033500487827348\n",
      "1050 0.4941147382743462\n",
      "1100 0.5486374928244143\n",
      "1150 0.5535532784472138\n",
      "1200 0.49129140610697397\n",
      "0 0.5441357525538517\n",
      "50 0.40539116542745507\n",
      "100 0.39289453225830134\n",
      "150 0.43227396392531303\n",
      "200 0.46305289905132\n",
      "250 0.39482780760767683\n",
      "300 0.47036495357251\n",
      "350 0.4092085421691329\n",
      "400 0.4130051428476167\n",
      "450 0.4168947347664526\n",
      "500 0.43876063740792576\n",
      "550 0.4449797659100025\n",
      "600 0.43673351758727713\n",
      "650 0.4191843597160548\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-be739c864ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlog_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ce26dcb10231>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequence, output_sequence)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdec_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9519b6295043>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequence)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cross_entropy(log_predictions, targets, alphabet):\n",
    "    \"\"\" Cross entropy loss for sequences\n",
    "    Parameters\n",
    "    ---------\n",
    "    log_predictions: Tensor NxTxH\n",
    "        Log probabilities\n",
    "    targets: Tensor NxT\n",
    "        True index-encoded translations\n",
    "    alphabet: Alphabet\n",
    "        Alphabet object\n",
    "    \n",
    "    \"\"\"\n",
    "    length_mask = alphabet.get_mask(targets)\n",
    "    targets_mask = torch.zeros_like(log_predictions).scatter_(2, targets.view(*targets.shape, 1), 1.0)\n",
    "    mask = targets_mask * length_mask.view(*length_mask.shape, 1)\n",
    "    #print(mask.sum(1, keepdim=True).sum(2, keepdim=True))\n",
    "    return (log_predictions * mask / (mask.sum(2, keepdim=True).sum(1, keepdim=True) * -log_predictions.size(0))).sum()\n",
    " \n",
    "cur_loss = 0\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for i, (x, y) in enumerate(batch_iterator(train_X, train_Y)):\n",
    "        inputs = Variable(torch.from_numpy(x))\n",
    "        targets = Variable(torch.from_numpy(y))\n",
    "        log_predictions = model(inputs, targets)\n",
    "        #print(x)\n",
    "        loss = cross_entropy(log_predictions, targets, be)\n",
    "        #print(loss.data, log_predictions.data.min())\n",
    "        loss.backward()\n",
    "        cur_loss = 0.9 * cur_loss + 0.1 * loss.data[0]\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if i % 50 == 0:\n",
    "            print(i, cur_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'зялёны_END_'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.translate(\"зеленый\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-16-c58232b29394>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-c58232b29394>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def translate(model, word, strategy='', max_length=30):\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translate(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import editdistance as ed\n",
    "\n",
    "\n",
    "scs = []\n",
    "with open(TEST_FILE, \"r\") as ftr:\n",
    "    for ruw, bew in map(lambda x: x.split(), \n",
    "                        filter(lambda x: len(x.split()) == 2, tqdm_notebook(ftr.readlines()))):\n",
    "        res = model.translate(ruw)\n",
    "        scs.append(ed.eval(bew, res[:-5]))\n",
    "        #print(ruw, bew, res)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4730290456431536"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "поражением\tпаразай\r\n",
      "местному\tмясцовым\r\n",
      "испанских\tіспанскіх\r\n",
      "сорока\tсарока\r\n",
      "способна\tздольная\r\n",
      "факторы\tфактары\r\n",
      "высадки\tвысадкі\r\n",
      "аргентина\tаргенціна\r\n",
      "феликс\tфелікс\r\n",
      "финальном\tфінальным\r\n",
      "фактором\tфактарам\r\n",
      "оригинального\tарыгінальнага\r\n",
      "древнейших\tнайстаражытных\r\n",
      "художественным\tмастацкім\r\n",
      "резиденции\tрэзідэнцыі\r\n",
      "кораблях\tкараблях\r\n",
      "православие\tправаслаўе\r\n",
      "мл\tмл\r\n",
      "гражданский\tграмадзянскі\r\n",
      "транспортного\tтранспартнага\r\n",
      "листьями\tлісцем\r\n",
      "поврежд\tповрежд\r\n",
      "выехал\tвыехаў\r\n",
      "сицилии\tсіцыліі\r\n",
      "чтение\tчытанне\r\n",
      "повсеместно\tпаўсюдна\r\n",
      "украшения\tўпрыгажэнні\r\n",
      "передали\tперадалі\r\n",
      "проявления\tпраявы\r\n",
      "вокалист\tвакаліст\r\n",
      "склад\tсклад\r\n",
      "уголовное\tкрымінальная\r\n",
      "работало\tпрацавала\r\n",
      "ушел\tсышоў\r\n",
      "запросов\tзапытаў\r\n",
      "спектакля\tспектакля\r\n",
      "продать\tпрадаць\r\n",
      "сл\tсл\r\n",
      "ленинского\tленінскага\r\n",
      "землями\tземлямі\r\n",
      "свидетелей\tсведак\r\n",
      "существующей\tіснуючай\r\n",
      "частного\tпрыватнага\r\n",
      "образцу\tузоры\r\n",
      "отмечали\tадзначалі\r\n",
      "воздействием\tуздзеяннем\r\n",
      "категорически\tкатэгарычна\r\n",
      "дальнейшие\tдалейшыя\r\n",
      "сообщается\tпаведамляецца\r\n",
      "периоде\tперыядзе\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 50 data/ru-be.txt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "cc4ad6e3a9934f4c9b49d8016c85dcb3": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
