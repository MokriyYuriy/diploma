{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'data/ru-be-train.txt'\n",
    "TEST_FILE = 'data/ru-be-test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    " \n",
    "class Alphabet:\n",
    "    START = '__START__'\n",
    "    END = '_END_'\n",
    " \n",
    "    def __init__(self, max_length=MAX_LENGTH):\n",
    "        \"\"\"Initialize the class which works with letter and index representations of sequences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_length : int\n",
    "            The largest permitted length for sequence. Longer sequences are cropped.\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.letter2index_ = {Alphabet.START : 0, Alphabet.END : 1}\n",
    "        self.index2letter_ = [Alphabet.START, Alphabet.END]\n",
    "        \n",
    "    def get_index(self, letter):\n",
    "        if letter not in self.letter2index_:\n",
    "            self.letter2index_[letter] = len(self.index2letter_)\n",
    "            self.index2letter_.append(letter)\n",
    "        return self.letter2index_[letter]\n",
    "    \n",
    "    @property\n",
    "    def start_index(self):\n",
    "        return self.letter2index_[Alphabet.START]\n",
    "    \n",
    "    @property\n",
    "    def end_index(self):\n",
    "        return self.letter2index_[Alphabet.END]\n",
    "    \n",
    "    def index2letter(self, x):\n",
    "        return ''.join(self.index2letter_[index] for index in x)\n",
    "    \n",
    "    def letter2index(self, word):\n",
    "        lst = [self.get_index(letter) for letter in word]\n",
    "        return lst[:self.max_length - 1] + [self.get_index(Alphabet.END)] * max(1, self.max_length - len(lst))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index2letter_)\n",
    "    \n",
    "    # torch utils\n",
    "    def get_length(self, input_sequence):\n",
    "        \"\"\"Infers the lengths of sequences in batch\n",
    "        \n",
    "        \"\"\"\n",
    "        return (input_sequence == self.end_index).max(dim=1)[1] + 1\n",
    "    \n",
    "    def get_mask(self, input_sequence):\n",
    "        return (torch.cumsum(input_sequence == self.end_index, dim=1) < 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru = Alphabet()\n",
    "be = Alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pair_dataset(filename, alph1, alph2):\n",
    "    x, y = [], []\n",
    "    with open(filename, 'r') as ftr:\n",
    "        for line in ftr:\n",
    "            try:\n",
    "                word1, word2 = line.split()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            x.append(alph1.letter2index(word1))\n",
    "            y.append(alph2.letter2index(word2))\n",
    "    return np.array(x), np.array(y)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = load_pair_dataset(TRAIN_FILE, ru, be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seq2seq_softmax_with_mask(entries, mask):\n",
    "    entries = torch.where(mask > 0.5, entries[:,:,0], -np.inf)\n",
    "    maxs = entries.max(1, keepdim=True)[0]\n",
    "    #print(entries.shape, maxs.shape, mask.shape)\n",
    "    entries = torch.exp(entries - maxs) * mask\n",
    "    print(entries.max(1))\n",
    "    return entries / (entries.sum(dim=1, keepdim=True) + 1e-15)\n",
    "\n",
    "\n",
    "class MultiplicativeAttentionWithMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiplicativeAttentionWithMask, self).__init__()\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_hiddens, encoder_mask):\n",
    "        \"\"\"\n",
    "        decoder_hidden: NxH\n",
    "        encoder_hiddens: NxTxH\n",
    "        \n",
    "        \"\"\"\n",
    "        weights = torch.bmm(encoder_hiddens, decoder_hidden.unsqueeze(2))\n",
    "        weights = seq2seq_softmax_with_mask(weights, encoder_mask)\n",
    "        return torch.bmm(encoder_hiddens.transpose(1, 2), weights.unsqueeze(2))[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleGRUEncoder(nn.Module):\n",
    "    def __init__(self, alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUEncoder, self).__init__()\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(self.alphabet), embedding_dim=embedding_size)\n",
    "        self.gru = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_sequence):\n",
    "        batch_size = input_sequence.size(0)\n",
    "        embeddings = self.embedding(input_sequence)\n",
    "        out, _ = self.gru(embeddings)\n",
    "        return out, self.alphabet.get_mask(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGRUDecoderWithAttention(nn.Module):\n",
    "    def __init__(self, alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUDecoderWithAttention, self).__init__()\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(alphabet), embedding_dim=embedding_size)\n",
    "        self.gru_cell = nn.GRUCell(input_size=embedding_size + hidden_size, hidden_size=hidden_size)\n",
    "        self.logit_linear = nn.Linear(hidden_size, len(alphabet))\n",
    "        self.attention = MultiplicativeAttentionWithMask()\n",
    "        \n",
    "    def forward(self, token, prev_h, encoder_hs, encoder_mask):\n",
    "        embedding = self.embedding(token)\n",
    "        attention = self.attention(prev_h, encoder_hs, encoder_mask)\n",
    "        #print(attention.shape, embedding.shape)\n",
    "        h = self.gru_cell(torch.cat((embedding, attention), dim=1), prev_h)\n",
    "        out = self.logit_linear(h)\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleGRUSupervisedSeq2Seq(nn.Module):\n",
    "    def __init__(self, src_alphabet, dst_alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUSupervisedSeq2Seq, self).__init__()\n",
    "        self.encoder = SimpleGRUEncoder(src_alphabet, embedding_size, hidden_size)\n",
    "        self.h_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.decoder = SimpleGRUDecoderWithAttention(dst_alphabet, embedding_size, hidden_size)\n",
    "        \n",
    "    def start(self, batch_size):\n",
    "        return Variable(torch.from_numpy(np.repeat(self.decoder.alphabet.start_index, batch_size)))\n",
    "    \n",
    "    def middle_layer(self, out, mask):\n",
    "        #print(mask.sum(1))\n",
    "        return F.tanh(self.h_linear(out[range(out.shape[0]), mask.sum(1).long() - 1]))\n",
    "    \n",
    "    def forward(self, input_sequence, output_sequence):\n",
    "        enc_out, enc_mask = self.encoder(input_sequence)\n",
    "        dec_h = self.middle_layer(enc_out, enc_mask)\n",
    "        logits = []\n",
    "        for x in itertools.chain((self.start(output_sequence.size(0)),), output_sequence.transpose(0, 1)[:-1]):\n",
    "            out, dec_h = self.decoder(x, dec_h, enc_out, enc_mask)\n",
    "            logits.append(out)\n",
    "        return F.log_softmax(torch.stack(logits, dim=1), dim=-1)\n",
    "    \n",
    "    def translate(self, word, strategy='', max_length=30):\n",
    "        self.eval()\n",
    "        input_sequence = Variable(torch.from_numpy(np.array([model.encoder.alphabet.letter2index(word)])))\n",
    "        #print(input_sequence.shape)\n",
    "        enc_out, enc_mask = self.encoder(input_sequence)\n",
    "        hidden = self.middle_layer(enc_out, enc_mask)\n",
    "        token = self.start(1)\n",
    "        #print(token.shape, hidden.shape)\n",
    "        lst = []\n",
    "        for i in range(max_length):\n",
    "            out, hidden = self.decoder(token, hidden, enc_out, enc_mask)\n",
    "            token = out.max(1)[1]\n",
    "            #print(token, out)\n",
    "            lst.append(token.data[0])\n",
    "            if token.data[0] == self.decoder.alphabet.end_index:\n",
    "                break\n",
    "        return ''.join(model.decoder.alphabet.index2letter(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iterator(X, Y=None, batch_size=32):\n",
    "    assert Y is None or X.shape[0] == Y.shape[0]\n",
    "    ind = np.arange(X.shape[0])\n",
    "    np.random.shuffle(ind)\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        if Y is not None:\n",
    "            yield X[ind[i:i + batch_size]], Y[ind[i:i + batch_size]]\n",
    "        else:\n",
    "            yield X[ind[i:i + batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SimpleGRUSupervisedSeq2Seq(ru, be, 65, 256)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of SimpleGRUSupervisedSeq2Seq(\n",
       "  (encoder): SimpleGRUEncoder(\n",
       "    (embedding): Embedding(35, 65)\n",
       "    (gru): GRU(65, 256, batch_first=True)\n",
       "  )\n",
       "  (h_linear): Linear(in_features=256, out_features=256)\n",
       "  (decoder): SimpleGRUDecoderWithAttention(\n",
       "    (embedding): Embedding(65, 65)\n",
       "    (gru_cell): GRUCell(321, 256)\n",
       "    (logit_linear): Linear(in_features=256, out_features=65)\n",
       "    (attention): MultiplicativeAttentionWithMask(\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4e84a3bd55b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlog_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-ce26dcb10231>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequence, output_sequence)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-4b096b664251>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token, prev_h, encoder_hs, encoder_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(attention.shape, embedding.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-3ee5c12e4fcb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_hidden, encoder_hiddens, encoder_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \"\"\"\n\u001b[1;32m     20\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq_softmax_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hiddens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-3ee5c12e4fcb>\u001b[0m in \u001b[0;36mseq2seq_softmax_with_mask\u001b[0;34m(entries, mask)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq2seq_softmax_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmaxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(entries.shape, maxs.shape, mask.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmaxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'where'"
     ]
    }
   ],
   "source": [
    "def cross_entropy(log_predictions, targets, alphabet):\n",
    "    \"\"\" Cross entropy loss for sequences\n",
    "    Parameters\n",
    "    ---------\n",
    "    log_predictions: Tensor NxTxH\n",
    "        Log probabilities\n",
    "    targets: Tensor NxT\n",
    "        True index-encoded translations\n",
    "    alphabet: Alphabet\n",
    "        Alphabet object\n",
    "    \n",
    "    \"\"\"\n",
    "    length_mask = alphabet.get_mask(targets)\n",
    "    targets_mask = torch.zeros_like(log_predictions).scatter_(2, targets.view(*targets.shape, 1), 1.0)\n",
    "    mask = targets_mask * length_mask.view(*length_mask.shape, 1)\n",
    "    #print(mask.sum(1, keepdim=True).sum(2, keepdim=True))\n",
    "    return (log_predictions * mask / (mask.sum(2, keepdim=True).sum(1, keepdim=True) * -log_predictions.size(0))).sum()\n",
    " \n",
    "cur_loss = 0\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for i, (x, y) in enumerate(batch_iterator(train_X, train_Y)):\n",
    "        inputs = Variable(torch.from_numpy(x))\n",
    "        targets = Variable(torch.from_numpy(y))\n",
    "        log_predictions = model(inputs, targets)\n",
    "        #print(x)\n",
    "        loss = cross_entropy(log_predictions, targets, be)\n",
    "        #print(loss.data, log_predictions.data.min())\n",
    "        loss.backward()\n",
    "        cur_loss = 0.9 * cur_loss + 0.1 * loss.data[0]\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if i % 50 == 0:\n",
    "            print(i, cur_loss)\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.translate(\"зеленый\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-16-c58232b29394>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-c58232b29394>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def translate(model, word, strategy='', max_length=30):\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translate(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "указателя паказальніка указаталя_END_\n",
      "развитые развітыя развітыя_END_\n",
      "томский томскі томскі_END_\n",
      "софией сафіяй сафіей_END_\n",
      "иски пазовы іскі_END_\n",
      "сдаться здацца сдатацца_END_\n",
      "дюка дзюка дюка_END_\n",
      "врожд врожд врожд_END_\n",
      "груз груз груз_END_\n",
      "стартовом стартавым стартавам_END_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import editdistance as ed\n",
    "\n",
    "\n",
    "scs = []\n",
    "with open(TEST_FILE, \"r\") as ftr:\n",
    "    for ruw, bew in map(lambda x: x.split(), \n",
    "                        filter(lambda x: len(x.split()) == 2, tqdm_notebook(ftr.readlines()[:10]))):\n",
    "        res = model.translate(ruw)\n",
    "        scs.append(ed.eval(bew, res[:-5]))\n",
    "        print(ruw, bew, res)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4730290456431536"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "поражением\tпаразай\r\n",
      "местному\tмясцовым\r\n",
      "испанских\tіспанскіх\r\n",
      "сорока\tсарока\r\n",
      "способна\tздольная\r\n",
      "факторы\tфактары\r\n",
      "высадки\tвысадкі\r\n",
      "аргентина\tаргенціна\r\n",
      "феликс\tфелікс\r\n",
      "финальном\tфінальным\r\n",
      "фактором\tфактарам\r\n",
      "оригинального\tарыгінальнага\r\n",
      "древнейших\tнайстаражытных\r\n",
      "художественным\tмастацкім\r\n",
      "резиденции\tрэзідэнцыі\r\n",
      "кораблях\tкараблях\r\n",
      "православие\tправаслаўе\r\n",
      "мл\tмл\r\n",
      "гражданский\tграмадзянскі\r\n",
      "транспортного\tтранспартнага\r\n",
      "листьями\tлісцем\r\n",
      "поврежд\tповрежд\r\n",
      "выехал\tвыехаў\r\n",
      "сицилии\tсіцыліі\r\n",
      "чтение\tчытанне\r\n",
      "повсеместно\tпаўсюдна\r\n",
      "украшения\tўпрыгажэнні\r\n",
      "передали\tперадалі\r\n",
      "проявления\tпраявы\r\n",
      "вокалист\tвакаліст\r\n",
      "склад\tсклад\r\n",
      "уголовное\tкрымінальная\r\n",
      "работало\tпрацавала\r\n",
      "ушел\tсышоў\r\n",
      "запросов\tзапытаў\r\n",
      "спектакля\tспектакля\r\n",
      "продать\tпрадаць\r\n",
      "сл\tсл\r\n",
      "ленинского\tленінскага\r\n",
      "землями\tземлямі\r\n",
      "свидетелей\tсведак\r\n",
      "существующей\tіснуючай\r\n",
      "частного\tпрыватнага\r\n",
      "образцу\tузоры\r\n",
      "отмечали\tадзначалі\r\n",
      "воздействием\tуздзеяннем\r\n",
      "категорически\tкатэгарычна\r\n",
      "дальнейшие\tдалейшыя\r\n",
      "сообщается\tпаведамляецца\r\n",
      "периоде\tперыядзе\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 50 data/ru-be.txt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
