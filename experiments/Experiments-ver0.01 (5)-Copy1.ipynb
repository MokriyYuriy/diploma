{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/c5/0763a145e051ce7c84c128621693d1c5dfad5a42d551e8d79742261002e2/torch-0.3.1-cp35-cp35m-manylinux1_x86_64.whl (496.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 496.4MB 2.3kB/s eta 0:00:01  7% |██▌                             | 38.6MB 35.4MB/s eta 0:00:13    10% |███▍                            | 52.1MB 39.0MB/s eta 0:00:12    13% |████▍                           | 68.3MB 26.1MB/s eta 0:00:17    14% |████▊                           | 73.2MB 26.8MB/s eta 0:00:16    15% |█████                           | 76.5MB 37.9MB/s eta 0:00:12    19% |██████▏                         | 95.2MB 40.8MB/s eta 0:00:10    20% |██████▍                         | 99.5MB 33.0MB/s eta 0:00:13    24% |████████                        | 122.5MB 21.3MB/s eta 0:00:18    27% |████████▊                       | 135.9MB 42.2MB/s eta 0:00:09    31% |██████████                      | 155.7MB 44.5MB/s eta 0:00:08    33% |██████████▉                     | 168.7MB 48.6MB/s eta 0:00:07    36% |███████████▋                    | 179.6MB 45.6MB/s eta 0:00:07    43% |██████████████                  | 215.7MB 37.5MB/s eta 0:00:08    43% |██████████████                  | 218.0MB 40.0MB/s eta 0:00:07    46% |███████████████                 | 231.5MB 25.5MB/s eta 0:00:11    52% |████████████████▉               | 261.7MB 44.2MB/s eta 0:00:06    58% |██████████████████▊             | 289.8MB 42.8MB/s eta 0:00:05    62% |████████████████████▏           | 312.1MB 37.5MB/s eta 0:00:05    72% |███████████████████████▎        | 360.4MB 40.9MB/s eta 0:00:04    74% |████████████████████████        | 372.3MB 36.0MB/s eta 0:00:04    75% |████████████████████████▎       | 376.3MB 34.8MB/s eta 0:00:04    76% |████████████████████████▍       | 378.3MB 36.9MB/s eta 0:00:04    77% |█████████████████████████       | 386.6MB 49.8MB/s eta 0:00:03B 48.1MB/s eta 0:00:03�█████▏     | 405.9MB 42.9MB/s eta 0:00:03��████████▋     | 412.0MB 42.8MB/s eta 0:00:02��█████████     | 417.5MB 45.8MB/s eta 0:00:02�████████████████▌    | 426.9MB 42.2MB/s eta 0:00:028% |████████████████████████████▏   | 437.4MB 26.4MB/s eta 0:00:03██████████████████████████▏   | 437.7MB 28.0MB/s eta 0:00:03��██████████████████████▎   | 438.0MB 30.3MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/c9/f4eb36734bffd36eb8095247d816cbe6aeca0a2b9218b78678288edfdb92/torchvision-0.2.0-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.6MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pyyaml (from torch)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy (from torch)\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/31/991207e6234b46a1228be970735ead9d6f06a298917d6f718c5e32e835bb/numpy-1.14.2-cp35-cp35m-manylinux1_x86_64.whl (12.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.1MB 104kB/s eta 0:00:01    90% |████████████████████████████▉   | 10.9MB 35.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six (from torchvision)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/52/8e27b9c54cb70d379244771a58483928b3a02db3c657d466ed84eb18f22b/Pillow-5.1.0-cp35-cp35m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 593kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/mavrandr/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, numpy, torch, six, pillow, torchvision\n",
      "Successfully installed numpy-1.14.2 pillow-5.1.0 pyyaml-3.12 six-1.11.0 torch-0.3.1 torchvision-0.2.0\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --user torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'data/ru-be-train.txt'\n",
    "TEST_FILE = 'data/ru-be-test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    " \n",
    "class Alphabet:\n",
    "    START = '__START__'\n",
    "    END = '_END_'\n",
    " \n",
    "    def __init__(self, max_length=MAX_LENGTH):\n",
    "        \"\"\"Initialize the class which works with letter and index representations of sequences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_length : int\n",
    "            The largest permitted length for sequence. Longer sequences are cropped.\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.letter2index_ = {Alphabet.START : 0, Alphabet.END : 1}\n",
    "        self.index2letter_ = [Alphabet.START, Alphabet.END]\n",
    "        \n",
    "    def get_index(self, letter):\n",
    "        if letter not in self.letter2index_:\n",
    "            self.letter2index_[letter] = len(self.index2letter_)\n",
    "            self.index2letter_.append(letter)\n",
    "        return self.letter2index_[letter]\n",
    "    \n",
    "    @property\n",
    "    def start_index(self):\n",
    "        return self.letter2index_[Alphabet.START]\n",
    "    \n",
    "    @property\n",
    "    def end_index(self):\n",
    "        return self.letter2index_[Alphabet.END]\n",
    "    \n",
    "    def index2letter(self, x, with_start_end=True):\n",
    "        result = []\n",
    "        for index in x[0 if with_start_end else 1:]:\n",
    "            if index == self.end_index:\n",
    "                if with_start_end:\n",
    "                    result.append(self.index2letter_[index])\n",
    "                break\n",
    "            result.append(self.index2letter_[index])\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def letter2index(self, word):\n",
    "        lst = [self.get_index(letter) for letter in word]\n",
    "        return [self.start_index] + lst[:self.max_length - 2] + [self.end_index] * max(1, self.max_length - len(lst) - 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index2letter_)\n",
    "    \n",
    "    # torch utils\n",
    "    def get_length(self, input_sequence):\n",
    "        \"\"\"Infers the lengths of the sequences in batch\n",
    "        \n",
    "        input_sequence: Tensor NxT\n",
    "        \n",
    "        returs: Tensor N\n",
    "        \"\"\"\n",
    "        return (input_sequence == self.end_index).max(dim=1)[1] + 1\n",
    "    \n",
    "    def get_mask(self, input_sequence):\n",
    "        \"\"\"Infers the mask of the sequences in batch\n",
    "        \n",
    "        input_sequence: Tensor NxT\n",
    "        \n",
    "        returns: Tensor NxT contained 0s and 1s.\n",
    "        \"\"\"\n",
    "        return (torch.cumsum(input_sequence == self.end_index, dim=1) < 2).float()\n",
    "    \n",
    "    def get_one_hot_repr(self, input_sequence):\n",
    "        \"\"\"Produces one_hot representation from label representation/\n",
    "        \n",
    "        input_sequence: LongTensor NxT\n",
    "        \n",
    "        returns: FloatTensor NxTxH\n",
    "        \"\"\"\n",
    "        \n",
    "        onehot = torch.FloatTensor(*input_sequence.shape, len(self)).zero_()\n",
    "        onehot.scatter_(2, input_sequence.unsqueeze(2), 1.)\n",
    "        \n",
    "        return onehot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru = Alphabet()\n",
    "be = Alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pair_dataset(filename, alph1, alph2):\n",
    "    x, y = [], []\n",
    "    with open(filename, 'r') as ftr:\n",
    "        for line in ftr:\n",
    "            try:\n",
    "                word1, word2 = line.split()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            x.append(alph1.letter2index(word1))\n",
    "            y.append(alph2.letter2index(word2))\n",
    "    return np.array(x), np.array(y)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y = load_pair_dataset(TRAIN_FILE, ru, be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot = torch.FloatTensor(2, 2, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indx = torch.LongTensor([[1, 4], [4, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function FloatTensor.scatter_>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.scatter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_softmax_with_mask(entries, mask):\n",
    "    entries = entries[:,:,0]\n",
    "    maxs = entries.max(1, keepdim=True)[0]\n",
    "    #print(entries.shape, maxs.shape, mask.shape)\n",
    "    entries = torch.exp(entries - maxs) * mask\n",
    "    return entries / (entries.sum(dim=1, keepdim=True) + 1e-15)\n",
    "\n",
    "\n",
    "class MultiplicativeAttentionWithMask(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MultiplicativeAttentionWithMask, self).__init__()\n",
    "        self.encoder_linear = nn.Linear(input_size, output_size)\n",
    "        self.decoder_linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_hiddens, encoder_mask):\n",
    "        \"\"\"\n",
    "        decoder_hidden: NxH\n",
    "        encoder_hiddens: NxTxH\n",
    "        \"\"\"\n",
    "        decoder_hidden_key = F.tanh(self.decoder_linear(decoder_hidden))\n",
    "        encoder_hiddens_keys = F.tanh(self.encoder_linear(encoder_hiddens))\n",
    "        weights = torch.bmm(encoder_hiddens_keys, decoder_hidden_key.unsqueeze(2))\n",
    "        weights = seq2seq_softmax_with_mask(weights, encoder_mask)\n",
    "        return torch.bmm(encoder_hiddens.transpose(1, 2), weights.unsqueeze(2))[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGRUEncoder(nn.Module):\n",
    "    def __init__(self, alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUEncoder, self).__init__()\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(self.alphabet), embedding_dim=embedding_size)\n",
    "        self.gru = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_sequence):\n",
    "        batch_size = input_sequence.size(0)\n",
    "        embeddings = self.embedding(input_sequence)\n",
    "        out, _ = self.gru(embeddings)\n",
    "        return out, self.alphabet.get_mask(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGRUDecoderWithAttention(nn.Module):\n",
    "    def __init__(self, alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUDecoderWithAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(alphabet), embedding_dim=embedding_size)\n",
    "        self.gru_cell = nn.GRUCell(input_size=embedding_size + hidden_size, hidden_size=hidden_size)\n",
    "        self.logit_linear = nn.Linear(hidden_size, len(alphabet))\n",
    "        self.attention = MultiplicativeAttentionWithMask(hidden_size, embedding_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "        \n",
    "    def forward(self, token, prev_h, encoder_hs, encoder_mask):\n",
    "        embedding = self.embedding(token)\n",
    "        attention = self.attention(prev_h, encoder_hs, encoder_mask)\n",
    "        #print(attention.shape, embedding.shape)\n",
    "        h = self.gru_cell(torch.cat((embedding, attention), dim=1), prev_h)\n",
    "        out = self.logit_linear(h)\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleGRUSupervisedSeq2Seq(nn.Module):\n",
    "    def __init__(self, src_alphabet, dst_alphabet, embedding_size, hidden_size):\n",
    "        super(SimpleGRUSupervisedSeq2Seq, self).__init__()\n",
    "        self.encoder = SimpleGRUEncoder(src_alphabet, embedding_size, hidden_size)\n",
    "        self.h_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.decoder = SimpleGRUDecoderWithAttention(dst_alphabet, embedding_size, hidden_size)\n",
    "        \n",
    "    def start(self, batch_size):\n",
    "        return Variable(torch.from_numpy(np.repeat(self.decoder.alphabet.start_index, batch_size)))\n",
    "    \n",
    "    '''\n",
    "    def middle_layer(self, out, mask):\n",
    "        #print(mask.sum(1))\n",
    "        return F.tanh(self.h_linear(out[range(out.shape[0]), mask.sum(1).long() - 1]))\n",
    "    '''\n",
    "    \n",
    "    def forward(self, input_sequence, output_sequence):\n",
    "        enc_out, enc_mask = self.encoder(input_sequence)\n",
    "        dec_h = self.decoder.init_hidden(input_sequence.size(0))\n",
    "        logits = []\n",
    "        for x in output_sequence.transpose(0, 1)[:-1]:\n",
    "            out, dec_h = self.decoder(x, dec_h, enc_out, enc_mask)\n",
    "            logits.append(out)\n",
    "        return F.log_softmax(torch.stack(logits, dim=1), dim=-1)\n",
    "    \n",
    "    def translate(self, word, strategy='', max_length=30, with_start_end=True):\n",
    "        if isinstance(word, str):\n",
    "            as_word = True\n",
    "            input_sequence = Variable(torch.from_numpy(np.array([model.encoder.alphabet.letter2index(word)])))\n",
    "        elif isinstance(word, torch.autograd.variable.Variable):\n",
    "            as_word = False\n",
    "            input_sequence = word\n",
    "        else:\n",
    "            assert False, \"word argument must be str or numpy array\"\n",
    "            \n",
    "        #print(input_sequence.shape)\n",
    "        enc_out, enc_mask = self.encoder(input_sequence)\n",
    "        hidden = self.decoder.init_hidden(input_sequence.size(0))\n",
    "        tokens = self.start(input_sequence.size(0))\n",
    "        #print(token.shape, hidden.shape)\n",
    "        lst = [tokens]\n",
    "        for i in range(max_length - 1):\n",
    "            out, hidden = self.decoder(tokens, hidden, enc_out, enc_mask)\n",
    "            tokens = out.max(1)[1]\n",
    "            #print(token, out)\n",
    "            lst.append(tokens)\n",
    "            if as_word and tokens.data[0] == self.decoder.alphabet.end_index:\n",
    "                break\n",
    "        if as_word:\n",
    "            return ''.join(model.decoder.alphabet.index2letter(\n",
    "                    [x.data[0] for x in lst], \n",
    "                    with_start_end=with_start_end)\n",
    "            )\n",
    "        else:\n",
    "            return torch.stack(lst).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iterator(X, Y=None, batch_size=32):\n",
    "    assert Y is None or X.shape[0] == Y.shape[0]\n",
    "    ind = np.arange(X.shape[0])\n",
    "    np.random.shuffle(ind)\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        if Y is not None:\n",
    "            yield X[ind[i:i + batch_size]], Y[ind[i:i + batch_size]]\n",
    "        else:\n",
    "            yield X[ind[i:i + batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'оспорен'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_src_words[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рынго'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.translate(val_src_words[21], with_start_end=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleGRUSupervisedSeq2Seq(ru, be, 65, 256)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of SimpleGRUSupervisedSeq2Seq(\n",
       "  (encoder): SimpleGRUEncoder(\n",
       "    (embedding): Embedding(35, 65)\n",
       "    (gru): GRU(65, 256, batch_first=True)\n",
       "  )\n",
       "  (h_linear): Linear(in_features=256, out_features=256)\n",
       "  (decoder): SimpleGRUDecoderWithAttention(\n",
       "    (embedding): Embedding(65, 65)\n",
       "    (gru_cell): GRUCell(321, 256)\n",
       "    (logit_linear): Linear(in_features=256, out_features=65)\n",
       "    (attention): MultiplicativeAttentionWithMask(\n",
       "      (encoder_linear): Linear(in_features=256, out_features=65)\n",
       "      (decoder_linear): Linear(in_features=256, out_features=65)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(CHECKPOINTS, 'state_dict_4_0.7777775635820685.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(log_predictions, targets, alphabet):\n",
    "    \"\"\" Cross entropy loss for sequences\n",
    "    Parameters\n",
    "    ---------\n",
    "    log_predictions: Tensor NxTxH\n",
    "        Log probabilities\n",
    "    targets: Tensor NxT\n",
    "        True index-encoded translations\n",
    "    alphabet: Alphabet\n",
    "        Alphabet object\n",
    "    \n",
    "    \"\"\"\n",
    "    length_mask = alphabet.get_mask(targets)\n",
    "    targets_mask = torch.zeros_like(log_predictions).scatter_(2, targets.view(*targets.shape, 1), 1.0)\n",
    "    mask = targets_mask * length_mask.view(*length_mask.shape, 1)\n",
    "    #print(mask.sum(1, keepdim=True).sum(2, keepdim=True))\n",
    "    return (log_predictions * mask / (mask.sum(2, keepdim=True).sum(1, keepdim=True) * -log_predictions.size(0))).sum()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_src_words = [ru.index2letter(x, with_start_end=False) for x in val_X]\n",
    "val_trg_words = [be.index2letter(y, with_start_end=False) for y in val_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_words = [ru.index2letter(x, with_start_end=False) for x in train_X[:500]]\n",
    "trg_words = [be.index2letter(y, with_start_end=False) for y in train_Y[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_accuracy(model, val_src_words, val_trg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINTS = './checkpoints'\n",
    "\n",
    "! mkdir -p {CHECKPOINTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-669-503d7dc8f79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"state_dict_{}_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_src_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_trg_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_compute_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-669-503d7dc8f79b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, train_X, train_Y, val_src_words, val_trg_words, checkpoints_folder, metrics_compute_freq, n_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mlog_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-321-5e1aa57af803>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequence, output_sequence)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-261-184253ccfc59>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token, prev_h, encoder_hs, encoder_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(attention.shape, embedding.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-259-5a0fa490f5d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_hidden, encoder_hiddens, encoder_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \"\"\"\n\u001b[1;32m     20\u001b[0m         \u001b[0mdecoder_hidden_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mencoder_hiddens_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hiddens_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq_softmax_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yury/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \"\"\"\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import editdistance as ed\n",
    "import time\n",
    "import os\n",
    "import nltk.translate.bleu_score as bl\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def compute_bleu_score(model, src_words, trg_words):\n",
    "    return _compute_metric_average(model, src_words, trg_words, lambda x, y: bl.sentence_bleu([list(x)], list(y)))\n",
    "\n",
    "def compute_editdistance(model, src_words, trg_words):\n",
    "    return _compute_metric_average(model, src_words, trg_words, ed.eval)\n",
    "\n",
    "def compute_accuracy(model, src_words, trg_words):\n",
    "    return _compute_metric_average(model, src_words, trg_words, lambda x, y: x == y)\n",
    "\n",
    "def _compute_metric_average(model, src_words, trg_words, metric):\n",
    "    scs = [metric(model.translate(x, with_start_end=False), y) for x, y in zip(tqdm_notebook(src_words), trg_words)]\n",
    "    return np.mean(scs)\n",
    "\n",
    "def train(model, opt, train_X, train_Y, val_src_words, val_trg_words, checkpoints_folder, metrics_compute_freq=50, n_epochs=7):\n",
    "    cur_loss = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        for i, (x, y) in enumerate(batch_iterator(train_X, train_Y)):\n",
    "            inputs = Variable(torch.from_numpy(x))\n",
    "            targets = Variable(torch.from_numpy(y))\n",
    "            log_predictions = model(inputs, targets)\n",
    "            #print(x)\n",
    "            loss = cross_entropy(log_predictions, targets[:,1:].contiguous(), be)\n",
    "            #print(loss.data, log_predictions.data.min())\n",
    "            loss.backward()\n",
    "            cur_loss = 0.9 * cur_loss + 0.1 * loss.data[0]\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            if (i + 1) % metrics_compute_freq == 0:\n",
    "                print(\"epoch: {} iter: {} loss: {}\".format(epoch, i, cur_loss))\n",
    "        model.eval() \n",
    "        val_score = compute_bleu_score(model, val_src_words, val_trg_words)\n",
    "        print(\"epoch: {} val_score: {} time: {}\"\n",
    "              .format(epoch, val_score, time.time() - start_time))\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoints_folder, \"state_dict_{}_{}.pth\".format(epoch, val_score)))\n",
    "                \n",
    "train(model, opt, train_X, train_Y, val_src_words, val_trg_words, checkpoints_folder=CHECKPOINTS, metrics_compute_freq=50, n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMDiscriminator(nn.Module):\n",
    "    def __init__(self, alph, embedding_size, hidden_size):\n",
    "        super(LSTMDiscriminator, self).__init__()\n",
    "        self.alph = alph\n",
    "        self.embedding = nn.Embedding(embedding_dim=embedding_size, num_embeddings=len(alph))\n",
    "        self.bilstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, input_sequence):\n",
    "        embedding = self.embedding(input_sequence)\n",
    "        out, _ = self.bilstm(embedding)\n",
    "        return F.sigmoid(self.output(out[range(out.size(0)), self.alph.get_length(input_sequence) - 1].view(out.size(0), -1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_discriminator(disc_model, gen_model, opt, alph_X, train_X, train_Y, n_epochs=50):\n",
    "    cur_loss = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        disc_model.train()\n",
    "        gen_model.eval()\n",
    "        start_time = time.time()\n",
    "        for i, (x, y) in enumerate(batch_iterator(train_X[:100], train_Y[:100])):\n",
    "            inputs = Variable(torch.from_numpy(x))\n",
    "            targets = Variable(torch.from_numpy(y))\n",
    "            real_data_pred = disc_model(targets)\n",
    "            #print(targets.shape, gen_model.translate(inputs).shape)\n",
    "            gen_data_pred = disc_model(gen_model.translate(inputs))\n",
    "            #print(targets, gen_model.translate(inputs), real_data_pred, gen_data_pred)\n",
    "            #print(gen_data_pred)\n",
    "            #print(real_data_pred)\n",
    "            loss = F.binary_cross_entropy(gen_data_pred, torch.zeros_like(gen_data_pred)) \\\n",
    "                    + F.binary_cross_entropy(real_data_pred, torch.ones_like(real_data_pred))\n",
    "            cur_loss = 0.9 * cur_loss + 0.1 * loss.data[0]\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            if i % 10 == 9:\n",
    "                print(loss.data[0])\n",
    "            #break\n",
    "        print(cur_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc = LSTMDiscriminator(be, 65, 128)\n",
    "disc_opt = optim.Adam(disc.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47828762354850773\n",
      "0.7891616330778266\n",
      "0.9927513984005869\n",
      "1.1246100995517252\n",
      "1.2097757312396695\n",
      "1.264631254033487\n",
      "1.298679733613282\n",
      "1.315615722915447\n",
      "1.3327620490002825\n",
      "1.3283503470036722\n",
      "1.3357163702143897\n",
      "1.3015101269327118\n",
      "1.2952145269594424\n",
      "1.276770088341116\n",
      "1.2837131696264008\n",
      "1.2676731819778375\n",
      "1.2707987941426044\n",
      "1.229980041669185\n",
      "1.211134419065387\n",
      "1.2125875161289557\n",
      "1.1641344943987744\n",
      "1.2033323353890424\n",
      "1.1905862552767312\n",
      "1.160494529600224\n",
      "1.1233999980764031\n",
      "1.1019565296386356\n",
      "1.0876009395734516\n",
      "1.090764420394066\n",
      "1.0215543484382592\n",
      "0.9934764123630544\n",
      "1.0085826131660256\n",
      "0.9832224847477753\n",
      "0.9864519969911502\n",
      "0.9845802245398967\n",
      "0.9435776073795903\n",
      "0.9810906967744041\n",
      "0.9470984337126809\n",
      "0.9522093755753093\n",
      "0.8778221385823783\n",
      "0.8356584701484652\n",
      "0.8129246926392784\n",
      "0.8318862313371707\n",
      "0.8050565543599587\n",
      "0.8164536657012731\n",
      "0.8888504459811123\n",
      "0.9235375377705614\n",
      "0.943011606540823\n",
      "0.9092179370736815\n",
      "0.946454079448224\n",
      "0.9943259457970866\n"
     ]
    }
   ],
   "source": [
    "train_discriminator(disc, model, disc_opt, ru, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__START__палемікі_END_'"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.translate(\"полемики\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_trg_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x, y in zip(val_src_words[:10], val_trg_words):\n",
    "    tr = model.translate(x[:-5])[:-5]\n",
    "    y = y[:-5]\n",
    "    \n",
    "    print(tr, y, ed.eval(tr, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translate(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import editdistance as ed\n",
    "\n",
    "\n",
    "scs = []\n",
    "with open(TEST_FILE, \"r\") as ftr:\n",
    "    for ruw, bew in map(lambda x: x.split(), \n",
    "                        filter(lambda x: len(x.split()) == 2, tqdm_notebook(ftr.readlines()[:2000]))):\n",
    "        res = model.translate(ruw)\n",
    "        scs.append(ed.eval(bew, res[:-5]))\n",
    "        print(ruw, bew, res)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip3 install --user editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! head -n 50 data/ru-be.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "395baf9f1d0c436f992107b47fffc605": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "bfb340ca25f740608b9c06845a563673": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
